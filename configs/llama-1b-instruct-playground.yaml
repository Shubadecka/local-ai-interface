model:
  name: unsloth/Meta-Llama-3.2-1B-bnb-4bit
  max_seq_length: 2048
  load_in_4bit: true
lora:
  r: 16
  lora_alpha: 16
  lora_dropout: 0.0
  target_modules:
  - q_proj
  - k_proj
  - v_proj
  - o_proj
  - gate_proj
  - up_proj
  - down_proj
training:
  num_epochs: 10
  batch_size: 4
  gradient_accumulation_steps: 4
  learning_rate: 0.0002
  warmup_steps: 5
  logging_steps: 5
  save_steps: 100
data:
  dataset: deepmind/code_contests
  split: train
  max_samples: 1000
output:
  run_name: llama-1b-instruct-playground
  output_dir: ./checkpoints
